{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "from tensorflow.python.framework.ops import disable_eager_execution, enable_eager_execution\n",
    "disable_eager_execution()\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '/mnt/home/raheppt1/projects/age_prediction')\n",
    "import numpy as np\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# tensorflow-gpu 2.1.0\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization, ReLU\n",
    "from tensorflow.keras.optimizers import *\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from dataset import AgeData\n",
    "from misc import utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GPU device.\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\";\n",
    "\n",
    "# Activate memory growth.\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General parameters.\n",
    "batch_size = 8\n",
    "image_size = [100, 120, 100]\n",
    "image_spacing = [1.5, 1.5, 1.5]\n",
    "\n",
    "logroot_dir = Path('../logs/keras/')\n",
    "checkpoint_dir = Path('/mnt/share/raheppt1/tf_models/age/keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 410 ids\n",
      "loaded 103 ids\n",
      "410 103\n"
     ]
    }
   ],
   "source": [
    "# Load training and validation data.\n",
    "# todo select split, ADNI/IXI\n",
    "age_data = AgeData(image_size,\n",
    "                   image_spacing,\n",
    "                   shuffle_training_images=True,\n",
    "                   save_debug_images=False)\n",
    "\n",
    "dataset_train = age_data.dataset_train()\n",
    "train_samples = dataset_train.num_entries()\n",
    "dataset_val = age_data.dataset_val()\n",
    "val_samples = dataset_val.num_entries()\n",
    "print(train_samples, val_samples)\n",
    "\n",
    "# Define training and validation datasets from generators.\n",
    "def train_gen():\n",
    "    data = dataset_train\n",
    "    i = 0\n",
    "    while i < data.num_entries():\n",
    "        sample = data.get_next()\n",
    "        # DHWC tensor format\n",
    "        image = sample['generators']['image'].transpose([1, 2, 3, 0])\n",
    "        image = image.astype('float32')\n",
    "        age = sample['generators']['age']\n",
    "        yield image, age\n",
    "        i += 1\n",
    "\n",
    "def val_gen():\n",
    "    data = dataset_val\n",
    "    i = 0\n",
    "    while i < data.num_entries():\n",
    "        sample = data.get_next()\n",
    "        image = sample['generators']['image'].transpose([1, 2, 3, 0])\n",
    "        image = image.astype('float32')\n",
    "        age = sample['generators']['age']\n",
    "        yield image, age\n",
    "        i += 1\n",
    "\n",
    "ds_train = tf.data.Dataset.from_generator(train_gen, \n",
    "                                          output_types=(tf.float32, tf.float32),\n",
    "                                          output_shapes=(tf.TensorShape((None, None, None, None)), \n",
    "                                                         tf.TensorShape((1, ))))\n",
    "ds_train = ds_train.batch(batch_size=batch_size)\n",
    "\n",
    "ds_val = tf.data.Dataset.from_generator(val_gen, \n",
    "                                        output_types=(tf.float32, tf.float32),\n",
    "                                        output_shapes=(tf.TensorShape((None, None, None, None)), \n",
    "                                                         tf.TensorShape((1, ))))\n",
    "ds_val = ds_val.batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminative_model(input_shape=(124, 124, 124, 1), \n",
    "                               lambda_l2=0.00005):\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(8, kernel_size=(3, 3, 3),  padding='same', input_shape=input_shape))\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(Conv3D(16, kernel_size=(3, 3, 3), padding='same'))\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(Conv3D(32, kernel_size=(3, 3, 3), padding='same'))\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(Conv3D(64, kernel_size=(3, 3, 3), padding='same'))\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(Conv3D(128, kernel_size=(3, 3, 3), padding='same'))\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1024, activation='relu',\n",
    "                    kernel_regularizer=tf.keras.regularizers.l2(lambda_l2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation='relu',\n",
    "                    kernel_regularizer=tf.keras.regularizers.l2(lambda_l2)))\n",
    "    model.add(Dense(1, activation='linear', bias_initializer=tf.constant_initializer(50.0)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_10 (Conv3D)           (None, 100, 120, 100, 8)  224       \n",
      "_________________________________________________________________\n",
      "re_lu_40 (ReLU)              (None, 100, 120, 100, 8)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_40 (MaxPooling (None, 50, 60, 50, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 50, 60, 50, 16)    3472      \n",
      "_________________________________________________________________\n",
      "re_lu_41 (ReLU)              (None, 50, 60, 50, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_41 (MaxPooling (None, 25, 30, 25, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_12 (Conv3D)           (None, 25, 30, 25, 32)    13856     \n",
      "_________________________________________________________________\n",
      "re_lu_42 (ReLU)              (None, 25, 30, 25, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_42 (MaxPooling (None, 12, 15, 12, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_13 (Conv3D)           (None, 12, 15, 12, 64)    55360     \n",
      "_________________________________________________________________\n",
      "re_lu_43 (ReLU)              (None, 12, 15, 12, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_43 (MaxPooling (None, 6, 7, 6, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_14 (Conv3D)           (None, 6, 7, 6, 128)      221312    \n",
      "_________________________________________________________________\n",
      "re_lu_44 (ReLU)              (None, 6, 7, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_44 (MaxPooling (None, 3, 3, 3, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 3456)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3456)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              3539968   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 4,359,505\n",
      "Trainable params: 4,359,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Training parameters.\n",
    "max_epochs = 3000\n",
    "learning_rate = 0.0001\n",
    "lambda_l2 = 0.00005\n",
    "run_name = 'disc_01'\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.999\n",
    "\n",
    "# Initialize tensorboard logdir.\n",
    "logdir = logroot_dir.joinpath(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + run_name)\n",
    "logdir = str(logdir)\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "# Save checkpoints. Early stopping, only save the best checkpoint.\n",
    "checkpoint_path = checkpoint_dir.joinpath(run_name,'cp.ckt')\n",
    "checkpoint_path = str(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 save_best_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "disc_model = build_discriminative_model(image_size + [1], lambda_l2)\n",
    "disc_model.compile(loss='mse', \n",
    "                   optimizer=Adam(learning_rate,\n",
    "                                  beta_1 = beta_1,\n",
    "                                  beta_2 = beta_2), \n",
    "                   metrics=['mse', 'mae'])\n",
    "disc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "hist_discriminative = disc_model.fit(ds_train, \n",
    "                                     epochs=max_epochs, \n",
    "                                     verbose=1,\n",
    "                                     validation_data=ds_val,\n",
    "                                     callbacks=[tensorboard_callback,\n",
    "                                                cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo test full probabilistic model\n",
    "def build_probmodel(input_shape=(124, 124, 124, 1)):\n",
    "    model = Sequential()\n",
    "    model.add(tfp.layers.Convolution3DReparameterization(8, kernel_size=(3, 3, 3),  padding='same', input_shape=input_shape))\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(tfp.layers.Convolution3DReparameterization(16, kernel_size=(3, 3, 3), padding='same'))\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(tfp.layers.Convolution3DReparameterization(32, kernel_size=(3, 3, 3), padding='same'))\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(tfp.layers.Convolution3DReparameterization(64, kernel_size=(3, 3, 3), padding='same'))\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(tfp.layers.Convolution3DReparameterization(128, kernel_size=(3, 3, 3), padding='same'))\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(tfp.layers.DenseReparameterization(1024, activation='relu'))\n",
    "    model.add(tfp.layers.DenseReparameterization(512, activation='relu'))\n",
    "    model.add(tfp.layers.DenseReparameterization(2, activation='linear'))\n",
    "    model.add(tfp.layers.DistributionLambda(\n",
    "              lambda t: tfp.distributions.Normal(loc=t[..., :1],\n",
    "                                                 scale=1e-3 + tf.math.softplus(0.05 * t[..., 1:]))))\n",
    "    #model.add(tfp.layers.DistributionLambda(lambda t: tfp.distributions.Independent(\n",
    "    #                                        tfp.distributions.Normal(loc=t, scale=1),\n",
    "    #                                        reinterpreted_batch_ndims=1)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image parameters\n",
    "image_size = [100, 120, 100]\n",
    "image_spacing = [1.5, 1.5, 1.5]\n",
    "\n",
    "# Parameters:\n",
    "batch_size = 8 # 16 8\n",
    "max_epochs = 2000\n",
    "# Adam\n",
    "learning_rate = 0.0001# 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_log_likelihood(y_true, y_pred):\n",
    "    neg_log_like = -y_pred.log_prob(y_true)\n",
    "    neg_log_like = tf.reduce_mean(input_tensor=neg_log_like)\n",
    "    return neg_log_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCNN Model:\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_reparameterization_50 (None, 100, 120, 100, 8)  440       \n",
      "_________________________________________________________________\n",
      "re_lu_65 (ReLU)              (None, 100, 120, 100, 8)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_65 (MaxPooling (None, 50, 60, 50, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_reparameterization_51 (None, 50, 60, 50, 16)    6928      \n",
      "_________________________________________________________________\n",
      "re_lu_66 (ReLU)              (None, 50, 60, 50, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_66 (MaxPooling (None, 25, 30, 25, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_reparameterization_52 (None, 25, 30, 25, 32)    27680     \n",
      "_________________________________________________________________\n",
      "re_lu_67 (ReLU)              (None, 25, 30, 25, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_67 (MaxPooling (None, 12, 15, 12, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_reparameterization_53 (None, 12, 15, 12, 64)    110656    \n",
      "_________________________________________________________________\n",
      "re_lu_68 (ReLU)              (None, 12, 15, 12, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_68 (MaxPooling (None, 6, 7, 6, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_reparameterization_54 (None, 6, 7, 6, 128)      442496    \n",
      "_________________________________________________________________\n",
      "re_lu_69 (ReLU)              (None, 6, 7, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_69 (MaxPooling (None, 3, 3, 3, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 3456)              0         \n",
      "_________________________________________________________________\n",
      "dense_reparameterization_32  (None, 1024)              7078912   \n",
      "_________________________________________________________________\n",
      "dense_reparameterization_33  (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dense_reparameterization_34  (None, 2)                 2050      \n",
      "_________________________________________________________________\n",
      "distribution_lambda_14 (Dist ((None, 1), (None, 1))    0         \n",
      "=================================================================\n",
      "Total params: 8,718,250\n",
      "Trainable params: 8,718,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Training parameters.\n",
    "max_epochs = 3000\n",
    "lr=0.001\n",
    "run_name = 'prob'\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.999\n",
    "\n",
    "# Initialize tensorboard logdir.\n",
    "logdir = logroot_dir.joinpath(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + run_name)\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=str(logdir))\n",
    "\n",
    "# Save checkpoints. Early stopping, only save the best checkpoint.\n",
    "checkpoint_path = checkpoint_dir.joinpath(run_name,'cp.ckt')\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=str(checkpoint_path),\n",
    "                                                 save_weights_only=True,\n",
    "                                                 save_best_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "bcnn_model = build_probmodel(image_size + [1])\n",
    "loss_fnc = create_loss(bcnn_model)\n",
    "bcnn_model.compile(loss=lambda t, y: batch_size*neg_log_likelihood(t, y), \n",
    "                   optimizer=Adam(learning_rate,\n",
    "                                  beta_1=beta_1,\n",
    "                                  beta_2=beta_2), \n",
    "                   metrics=['mse', 'mae'])\n",
    "print(\"BCNN Model:\")\n",
    "bcnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2 steps, validate on 1 steps\n",
      "1/2 [==============>...............] - ETA: 16s - loss: 70485471657984.0000 - mse: 2202671.0000 - mae: 1473.7245\n",
      "Epoch 00001: val_loss improved from inf to 1021412507648.00000, saving model to /mnt/share/raheppt1/tf_models/age/keras/prob/cp.ckt\n",
      "2/2 [==============================] - 36s 18s/step - loss: 35561685024768.0000 - mse: 1111302.5000 - mae: 797.3650 - val_loss: 1021412507648.0000 - val_mse: 31918.8047 - val_mae: 157.4292\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "# todo check loss function in regression example\n",
    "history = bcnn_model.fit(ds_train, \n",
    "                         epochs=n_epochs,\n",
    "                         steps_per_epoch=2,#train_samples//batch_size,\n",
    "                         validation_steps=1,#val_samples//batch_size,\n",
    "                         verbose=1,\n",
    "                         validation_data=ds_val,\n",
    "                         callbacks=[tensorboard_callback,\n",
    "                                    cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f17e80c2510>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcnn_model.predict(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo predict\n",
    "# todo quantile regression\n",
    "# todo normal output layer\n",
    "# mae for probabilistic output "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
