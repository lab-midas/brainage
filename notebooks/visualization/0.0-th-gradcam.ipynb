{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import torchvision.models as models\n",
    "\n",
    "from brainage.model.agemodel_2dslices import AgeModel2DSlices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = '/home/raheppt1/projects/brainage/brainage/model/outputs/2020-07-14/20-19-10/my-project/3k717qdf/checkpoints/epoch=58.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'train_ds' and 'val_ds'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f33520a0710e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAgeModel2DSlices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/brainage/lib/python3.7/site-packages/pytorch_lightning/core/saving.py\u001b[0m in \u001b[0;36mload_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, tags_csv, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHECKPOINT_HYPER_PARAMS_KEY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_model_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/brainage/lib/python3.7/site-packages/pytorch_lightning/core/saving.py\u001b[0m in \u001b[0;36m_load_model_state\u001b[0;34m(cls, checkpoint, *cls_args, **cls_kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcls_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwonlyargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mcls_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcls_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcls_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;31m# load the state_dict on the model automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'train_ds' and 'val_ds'"
     ]
    }
   ],
   "source": [
    "model = AgeModel2DSlices.load_from_checkpoint(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['epoch',\n 'global_step',\n 'pytorch-lightning_version',\n 'checkpoint_callback_best_model_score',\n 'checkpoint_callback_best_model_path',\n 'optimizer_states',\n 'lr_schedulers',\n 'state_dict',\n 'hparams_name',\n 'hyper_parameters']"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "list(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": ".1041,\n                       0.0048, -0.0880, -0.0495, -0.0327, -0.0287, -0.0555, -0.0113, -0.0557,\n                      -0.0141, -0.0388, -0.0341, -0.0350, -0.0347, -0.0528, -0.0506, -0.0026,\n                      -0.0240, -0.0130, -0.0154, -0.0328, -0.0064, -0.0635, -0.0304, -0.0150,\n                      -0.0040, -0.0191, -0.0822, -0.0013, -0.0166, -0.0175, -0.0155, -0.0074,\n                      -0.0467, -0.0040, -0.0155, -0.0325, -0.0030, -0.0374, -0.0273, -0.0044,\n                      -0.0150, -0.0188, -0.0119, -0.0628, -0.0093, -0.0576, -0.0455, -0.0091,\n                      -0.0600, -0.0816, -0.0327, -0.0247, -0.0184, -0.0235, -0.0311, -0.0510,\n                      -0.0246, -0.0038, -0.0101, -0.0598, -0.0408, -0.0283, -0.0284, -0.0605,\n                      -0.0497, -0.0351, -0.0269, -0.0273, -0.0201, -0.0614, -0.0204, -0.0437,\n                      -0.0360, -0.0087, -0.0535, -0.0548, -0.0842, -0.0169, -0.0109, -0.0392,\n                      -0.0346, -0.1356, -0.0420, -0.0266, -0.0252, -0.0310, -0.0208, -0.0239,\n                      -0.0061, -0.0222, -0.0401, -0.0549, -0.0228, -0.0280, -0.0313, -0.0131,\n                      -0.0381, -0.0582, -0.0304, -0.0539, -0.0036, -0.0606, -0.0253, -0.0151,\n                      -0.0220, -0.0282, -0.0250, -0.0158, -0.0067, -0.0101,  0.0287, -0.0302,\n                      -0.0467, -0.0518, -0.0099, -0.0261, -0.0592, -0.0488, -0.0137, -0.0369,\n                      -0.0341, -0.0384, -0.0077, -0.0237, -0.0546, -0.0021, -0.0038, -0.0480,\n                      -0.0040, -0.0350, -0.0098, -0.0270, -0.0894, -0.0060, -0.0263, -0.0558,\n                      -0.0035, -0.0302, -0.0132,  0.0100, -0.0342, -0.0484, -0.0250, -0.0082,\n                      -0.0578, -0.0238, -0.0078, -0.0613, -0.0303, -0.0214, -0.0095,  0.0048,\n                      -0.0485, -0.0358, -0.0468, -0.0482, -0.0512, -0.0164, -0.0073, -0.0125,\n                      -0.0262, -0.0317, -0.0106, -0.0298, -0.0762, -0.0824, -0.0390, -0.0634,\n                      -0.0290, -0.0212, -0.0407, -0.0049, -0.0353, -0.0095, -0.0253, -0.0329,\n                      -0.0016, -0.0269, -0.0599, -0.0368, -0.0073, -0.0646, -0.0352, -0.0297,\n                      -0.0097, -0.0388, -0.0025, -0.0547, -0.0090,  0.0013, -0.1112, -0.0613,\n                      -0.0422, -0.0821, -0.0114, -0.0200, -0.0079, -0.0114, -0.0543,  0.0073,\n                      -0.0297, -0.0301, -0.0391, -0.0369, -0.0861, -0.0701,  0.0040, -0.0597,\n                      -0.0423, -0.0484, -0.0477, -0.0369, -0.0313, -0.0099, -0.0968, -0.0408,\n                      -0.0641, -0.0247, -0.0381, -0.0253, -0.0510, -0.0126, -0.0365, -0.0222,\n                      -0.0229, -0.0162, -0.0202, -0.0279, -0.0010, -0.0158, -0.0223, -0.0196,\n                      -0.0048, -0.0575, -0.0554, -0.0041, -0.0100, -0.0144, -0.0579, -0.0500,\n                      -0.0202, -0.0473, -0.0559, -0.0521, -0.0040, -0.0462, -0.0287, -0.0132,\n                      -0.0113, -0.0548, -0.0269, -0.0449, -0.0016, -0.0360, -0.0777, -0.0255],\n                     device='cuda:0')),\n             ('net.layer4.2.bn2.running_mean',\n              tensor([ -8.3809,   5.2159,  -6.6480,  -5.1142,  -3.8849,  -2.9390,  -7.6582,\n                       -4.9720,  -7.3362,   0.5666,  -8.0500,  -8.4658,  -9.0449,   3.7284,\n                       -6.0686,  -2.0734, -11.9700,   2.1612,  -6.3551,  -5.6401,  -8.0229,\n                       -3.6981, -12.6367,  -1.8823,  -2.1108, -13.7730,  -7.0773,  -0.9789,\n                       -7.8921,  -0.7803,  -3.3161,  -8.2249, -12.9315, -12.6925,  -5.1308,\n                       -8.2614,  -0.7336,  -4.3586, -10.4177,  -9.4064,  -7.0312,  -9.6452,\n                       -8.2423, -13.2360,   6.5688,  -5.4513,   1.4076,   4.1407,  -5.9687,\n                       -2.4003, -10.4796,  -8.5611,  -0.8769,  -7.8981,  -0.7169,  -4.0353,\n                       -5.9574,  -2.8455,  -9.9817,  -2.0992,  -3.9459,  -9.1685,  -2.8501,\n                       -2.8175, -10.1347,  -9.4935,  -0.6067,   6.7811,  -3.3597, -14.3647,\n                       -6.1928,  -7.1969,  -7.8459,  -9.5162,  -5.8344,  -4.1178,   1.8346,\n                       -6.9278,  -4.5911,  -4.8821,  -5.3463,   6.1763, -13.7082,   1.8189,\n                       -6.6231,  -6.9537,   2.2794,  -3.6167,  -4.6689,  -6.4323,  -2.9296,\n                      -14.2750,  -4.9814,  -5.0699,  -1.6566,   6.0863,  -8.1982,  -2.7785,\n                       -7.3876,  -2.5876,  -3.0072,  -4.4436, -14.4702,  -8.3194,  -3.6493,\n                      -11.6215,  -0.3752, -10.4223, -13.6724,  -7.3672,  -1.1642,  -9.2529,\n                      -17.3349,  -8.8028,   6.3085,  -4.1724, -11.0439,  -7.6580,  -5.4138,\n                       -9.9792,  -8.0539,  -5.4000,  -5.8818, -14.4836,  -2.8399,  -4.8755,\n                       -6.7450,  -9.6529,  -7.6685,  -5.8922,   2.6243,  -2.1504,  -0.6746,\n                       -3.6957,  -8.5637,  -3.0552,  -1.8001,  -1.4808, -13.2546,  -5.4887,\n                        2.2899,   1.4246,   6.9367,  -7.4864,  -0.2532,  -3.4739,  -9.8103,\n                       -6.6313,  -6.0721,  -3.2619,  -5.6709,  -5.9071,  -3.7148,  -7.0925,\n                       -3.6666,   1.3205,   2.5614,  -5.6221,  -1.5523, -12.0187,  -7.8777,\n                       -7.6905,  -1.2006,  -5.4242,   1.4290,  -3.1136, -12.6815,  -5.8554,\n                       -2.7059,  -3.4674,  -4.7663,   1.9499, -10.0857,  -3.9788,  -1.5947,\n                        0.9143, -11.7018,  -3.7073, -10.0625,  -4.0669,  -3.4898,  -9.3602,\n                       -6.4745,  -6.3376,   0.5105,  -3.1545,  -6.4988,   2.2987,  -5.6119,\n                      -10.1293,  -6.8162,  -6.3164,  -5.9786,  -6.5097,  -6.6889,  -6.1123,\n                        3.3803,  -3.5404,  -7.0480,  -6.6185,  -6.4255,  -1.1470,   2.3107,\n                        0.2733,   0.8535,  -1.4351,  -0.1289, -11.9231,  -7.3113,  -3.2461,\n                      -14.6431,   2.5800,  -7.6598,  -3.4557,  -7.9261,  -0.7535,  -8.8269,\n                       -6.8983, -11.1830,  -1.4390, -12.5180,  -8.8918,   0.1009,   4.3692,\n                       -3.1654,  -0.4909,  -0.2437,   1.0192, -10.7011,  -5.5415,  -9.9728,\n                       -3.4036,   0.3965,  -0.8566,   0.8487,  -3.0420,  -3.3574,   5.0989,\n                       -4.0961, -12.1870, -11.7056,   0.2988,  -9.4604,  -5.7658,  -1.5445,\n                       -8.1107,  11.1272, -11.7344,  -5.2132,  -0.2534,  -1.3337,  -8.4449,\n                       -1.8256,  -5.2292,  -7.0172,  -3.1959, -13.2390,  -5.6586,   1.1744,\n                       -0.9230, -10.6630,  -4.9005, -13.1899,  -4.4360,  -5.4424,  -6.0421,\n                       -4.2500,  -8.8906,   2.1866, -10.1163,  -4.5050,  -3.2234,  -4.7027,\n                       -6.7566,  -4.3918,   1.6430,  -3.8521,   2.8710, -10.5714,  -4.4162,\n                       -4.0744,  -8.7267,  -7.1627,  -0.6557,  -7.3678,  -8.8744,  -9.2481,\n                       -4.6840,  -3.9395,   2.5483,   5.1913,  -1.0503,   1.0018, -12.7971,\n                      -10.7983, -10.3243,  -8.8427,  -3.6586,  -5.8543,  -9.0870,  -8.1510,\n                        4.4418,  -3.2434,   4.6603,  -2.4148,   3.5590,  -5.5709,  -2.6207,\n                       -9.1557,  -6.7233,  -6.7182,  -0.3682,  -7.7873,  -2.4308,  -8.0553,\n                       -2.5189,  -4.0966,   0.0750,  -5.4867,  -2.0927,  -1.4768,   8.8811,\n                       -0.9456,  -6.1773, -10.6949,  -4.1474,  -1.1071,  -3.9621,  -6.2655,\n                       -3.5358,  -4.2226,  -9.5246, -13.9500,  -0.8786,  -2.1984,   1.7533,\n                        0.0258, -11.6406,   3.5979,  -8.4838,   1.2326, -11.6465,  -0.3701,\n                      -10.1964,  -2.0078,  -8.4267,  -1.2049,  -1.0370,  -0.4195,   0.6314,\n                        0.7581,  -4.6721,  -5.2496,  -5.4951,  -9.3842,  -3.2622,   2.3296,\n                       -2.3562,   4.8368,  -9.7004,   1.0327,  -7.0936, -12.4514,   3.9960,\n                       -7.9990,  -2.7056,  -8.9379,   0.5427,   6.8392,  -7.9392,  -7.9111,\n                       -3.7479,  -3.4312,  -0.5829,   8.9131, -10.4243,  -5.3255,  -7.0148,\n                       -7.5635,  -1.8072,  -6.4485,   3.7984,  -6.3693,  -9.0855,  -2.4223,\n                       -1.5247,  -8.8127,  -4.1110,   7.1810,  -9.4909, -11.0638,  -7.8770,\n                       -2.9901,  -8.1943,  -1.3901,  -2.6888,  -2.5290,  -9.4086,  -4.4163,\n                       -5.4501,  -2.9490,  -0.2211,  -3.4598,  -7.2552,  -6.1991,  -1.1727,\n                       -4.9907,  -1.0668,  -9.0737,  -5.2614,  -8.4048,  -6.0709,  -0.3667,\n                       -3.5686,  -4.8729,  -0.7391,  -8.7609,  -6.1933,  -9.8116,  -3.5903,\n                       -9.2596,  -4.9315,  -1.3098,   1.6630,   2.4412,  -9.1369,   0.4029,\n                       -5.5908,  -8.8946,   3.7583,  -4.8067,  -5.9137,  -8.5106, -10.8309,\n                       -3.3250,   2.8059,  -3.4696,  -8.2865,  -6.1573,  -7.1394,  -6.1980,\n                       -4.6689,  -3.3955,  -4.5817, -11.4701,   0.4259,  -5.7336,  -9.9208,\n                      -10.2430,  -1.5783,  -9.6428,  -4.0445, -10.1527,  -5.0779,  -9.6621,\n                       -2.9100,  -2.2353,  -8.1943, -10.2484,  -3.0613,   8.3251,   8.2680,\n                       -3.3224,   4.1058, -10.7589,  -6.8749,  -6.3909,  -2.5432,  -7.7162,\n                       -4.4289, -10.6387,  -3.5731,   1.1336,  -4.1445,  -6.7749,   0.1425,\n                      -12.6801,  -1.1614,  -5.0517,  -7.2069, -11.5290,  -1.9434,  -5.1494,\n                       -3.7452,  -7.0053,  -2.5832, -11.5741,  -0.8209,  -4.8371,  -7.3911,\n                       -3.5718,  -4.8683,  -6.4444, -11.5016,  -3.1438,   2.6146,  -3.2970,\n                       -0.5064,  10.4589,  -7.7545,   1.3871,  -2.0812,  -4.6531,  -3.6724,\n                       -0.2971,  -4.0346,  -5.1708,  -1.9678,  -4.8184,  -7.9842,  -7.3413,\n                      -10.0032], device='cuda:0')),\n             ('net.layer4.2.bn2.running_var',\n              tensor([101.9746,  59.1410,  77.6118,  54.9316,  19.4163,  16.0906,  28.8517,\n                       47.7060, 112.2685,  15.7100,  66.1043,  34.0178,  95.1785,  15.0442,\n                       84.6927,  13.4381, 137.5056,  36.7477,  26.8488,  27.0432,  93.5296,\n                       32.5974, 127.4513,  19.8966,  22.1883,  54.2510,  27.2994,  16.5250,\n                       65.1300,  14.9465,  10.9622,  61.9623, 122.5928,  51.0533,  80.7639,\n                       34.4087,  18.5453, 124.2838, 111.2332,  36.3734,  18.3674,  70.0597,\n                       18.4580, 200.4279,   8.3543,  14.5105,  29.3368,  35.2373,  77.1232,\n                       26.1087, 129.0433,  39.7693, 118.2275, 116.1013,  32.3736,  25.2764,\n                       18.0199, 114.1582,  68.6923, 102.4677,  60.3361, 134.7945,   5.9149,\n                       26.4948, 150.8660,  27.0155,  22.1355,  14.5031,  83.2917, 188.9508,\n                       66.7242,  56.7384,  39.9292,  33.3503,  33.3659,  48.0155,  17.0510,\n                       31.5802,  80.7326,  70.8317, 144.9133,  20.1397, 115.0107,  15.4921,\n                       54.4013,  30.5405,  16.6722,  30.7135,  76.4135, 104.4548, 114.6962,\n                      161.5617,  40.8208,  56.9759,  28.6729,  27.3527, 123.6444,  31.7264,\n                       63.5060,  85.9007,  91.5165,  30.4500, 182.0520,  41.7991,  37.3574,\n                      150.8502,  27.0248,  62.5391, 212.4047,  43.8956,  41.1953,  45.8840,\n                      153.4757,  30.8213,  29.3874,  47.4211,  58.1144,  44.3654,  32.7435,\n                       24.1028,  27.0180,  86.1517,  43.5754, 171.2557,  33.3648,  35.2727,\n                       19.3119,  60.9501,  26.3372,  20.1896,  34.3660,  32.4477,  40.7133,\n                       23.1991,  86.3271,  27.6525,  43.3932,  34.7101, 184.1586,  61.9512,\n                       17.3477,  81.3914,  29.2843, 111.4100,  14.6998, 132.5864,  73.0224,\n                       70.1241,  82.8520,  22.0692,  38.3520,  24.0769,  27.0943,  27.7253,\n                       24.9871,  52.4981,  43.4928,  76.6414,  31.9254, 103.3874,  28.6265,\n                       25.6125, 128.2169,  94.4106,  33.5857,  31.2417, 124.0178,  75.0394,\n                       50.6989,  19.0444,  18.4933,  67.6188,  37.6185,  65.0604,  27.5517,\n                       23.7712, 121.0303, 122.2225,  64.8790,  35.4201,  17.3315, 142.0062,\n                       44.0282,  69.4937,  47.1639,  24.0589,  27.6510,  20.4154, 157.0106,\n                      153.8094,  23.0534,  40.3346, 107.1596,  25.3895,  31.4984,  93.5235,\n                       43.5081,  88.1807, 147.2189,  54.9711,  97.7398,  11.8304,  11.2305,\n                       45.5784,  88.9947,  15.9251,  17.3315, 215.4386,  14.3804,  17.9583,\n                      155.0698, 129.6934,  63.7063,  40.1302,  57.7052,   9.4979,  59.9220,\n                       82.6025,  71.8032,  93.6244, 129.5543, 118.4700,  18.9794,  10.2976,\n                      110.5996,  15.9060,  12.9019,  52.7780, 154.5978,  48.5241,  25.0919,\n                       21.8738,  87.5847,  24.9444, 109.7407,  34.7571,  42.1550,  26.0738,\n                       33.2609, 105.0319, 112.3683,  20.0332,  43.1015, 136.0429,  14.7849,\n                       82.5556,  26.4636, 120.0373,  17.3694, 106.2013,  35.7632,  45.3188,\n                       25.5383,  95.2232,  33.7862,  55.7391, 121.6814,  63.3660,  16.5810,\n                       21.9930, 176.7814,  80.1627, 134.3306,  30.4221,  25.2046,  38.8509,\n                       48.8959,  55.9567,  20.7272, 136.2462,  29.9253,  21.6844,  35.8820,\n                       65.0240,  33.0824,  19.7075, 120.5051,  11.3501,  63.4866,  27.6279,\n                      106.1008,  33.5804,  50.7202,  18.9342,  72.4895,  52.2244, 149.3511,\n                       69.8946,  36.8005,  25.2711,  28.3799,  13.5536,  33.3153,  43.2243,\n                      176.1026, 146.0439, 136.9458,  15.0931,  29.3430,  38.6251,  15.2337,\n                        9.6926,  64.9827,  67.9622,  72.1730,  34.0927,  38.2529,  77.7373,\n                       84.3053,  58.6733,  36.6482,  69.7740,  34.8209,  32.8786,  30.8547,\n                       20.3168,  55.2934,  26.6457,  18.4682,  46.8305,  46.9017,  35.1738,\n                       20.8879,  21.6111, 123.3258,  31.6579, 105.3079,  32.4042, 123.6941,\n                       86.1321,  46.5877,  56.2066, 163.0556,  80.3490,  89.7909,  17.6836,\n                       13.2306,  78.1699,   8.6858,  61.2049,  19.0816,  69.1002,  47.9553,\n                      125.6884,  97.7738,  53.8917,  50.3650,  45.1767,  76.6976,  49.9714,\n                       15.5944,  24.3820, 130.6335,  35.2263,  46.8366,  27.4090,  51.0503,\n                       21.9237,  15.0294,  74.1146,  40.6581,  65.2379, 178.1839,  17.9375,\n                       83.7229,  54.4574,  81.1411,  35.8255,  18.7177,  82.8206,  82.0975,\n                       38.7693,  61.0100,  31.5910,  27.0205,  65.7583,  62.0697,  49.9107,\n                       74.6788,  56.7243,  44.5615,  23.1581, 117.1896,  58.6667,  47.2519,\n                       19.8983, 133.0995,  65.3348,  10.8138,  83.5707, 143.6921,  42.4576,\n                      120.0079,  62.8962,  81.9509,  14.9751,  62.8800,  21.3815,  30.3685,\n                       31.4144,  14.9123,  20.5074,  23.4558,  21.9756,  36.3778,  24.6097,\n                      121.7276,  25.8719,  38.1954,  33.0293,  39.9570,  20.0617,  22.2037,\n                       31.3889, 121.5549,  27.3264,  26.8879,   9.3194, 166.5730,  31.7641,\n                       30.8674,  23.5191,  47.8809,  38.7468,  35.6028,  28.0914,  18.5439,\n                      131.1754,  57.4111,   7.9143,  38.0172,  97.0876,  29.3483, 103.6295,\n                       21.5803,  24.4577,  89.3746,  26.2775,  30.9713,  95.2866, 131.0825,\n                      100.9783,  70.8487,  85.0068,  36.9992,  22.5641,  68.3350,  91.4332,\n                      133.6432,   5.2863,  45.6584,  90.2514,  45.8883, 143.6932,  97.0416,\n                       18.5869,  15.8713,  54.5128, 173.8084,  10.4680,  16.5458, 103.0912,\n                       32.2176,  55.2963,  97.2412,  42.3712,  19.8051,   9.5917,  33.4422,\n                      131.9303, 147.5311,  17.0651,  20.3967,  20.1928,  28.3939,  52.7875,\n                      217.0599,  42.4582,  28.4796, 110.6606, 125.1788,  16.9082,  19.2972,\n                       73.1091,  63.1777,  60.6984,  52.2578,   9.1878,  21.3695,  66.1694,\n                       25.5863,  20.4009,  96.1015, 130.9120,  25.5962,  12.0377,  21.3614,\n                       16.1286,  11.2979,  31.6058, 136.7194,  27.8672,  24.3209,  15.4586,\n                       20.1776,  41.6001,  19.4137,  16.4283, 139.1712,  75.3608,  71.9415,\n                       45.0915], device='cuda:0')),\n             ('net.layer4.2.bn2.num_batches_tracked',\n              tensor(73919, device='cuda:0')),\n             ('net.layer4.2.conv3.weight',\n              tensor([[[[-0.0200]],\n              \n                       [[-0.0623]],\n              \n                       [[ 0.0386]],\n              \n                       ...,\n              \n                       [[ 0.0196]],\n              \n                       [[-0.0096]],\n              \n                       [[-0.0656]]],\n              \n              \n                      [[[ 0.0470]],\n              \n                       [[-0.0731]],\n              \n                       [[ 0.0143]],\n              \n                       ...,\n              \n                       [[ 0.0514]],\n              \n                       [[ 0.0580]],\n              \n                       [[ 0.0508]]],\n              \n              \n                      [[[ 0.0463]],\n              \n                       [[-0.0271]],\n              \n                       [[-0.0227]],\n              \n                       ...,\n              \n                       [[ 0.0554]],\n              \n                       [[-0.0243]],\n              \n                       [[ 0.0261]]],\n              \n              \n                      ...,\n              \n              \n                      [[[ 0.0526]],\n              \n                       [[-0.0671]],\n              \n                       [[ 0.0538]],\n              \n                       ...,\n              \n                       [[ 0.0395]],\n              \n                       [[-0.0149]],\n              \n                       [[ 0.0544]]],\n              \n              \n                      [[[ 0.0191]],\n              \n                       [[-0.0270]],\n              \n                       [[ 0.0193]],\n              \n                       ...,\n              \n                       [[ 0.0178]],\n              \n                       [[ 0.0251]],\n              \n                       [[ 0.0292]]],\n              \n              \n                      [[[ 0.0654]],\n              \n                       [[ 0.0227]],\n              \n                       [[ 0.0034]],\n              \n                       ...,\n              \n                       [[ 0.0547]],\n              \n                       [[ 0.1156]],\n              \n                       [[ 0.0513]]]], device='cuda:0')),\n             ('net.layer4.2.bn3.weight',\n              tensor([0.9056, 1.0184, 1.0107,  ..., 1.0110, 1.0198, 1.0051], device='cuda:0')),\n             ('net.layer4.2.bn3.bias',\n              tensor([-0.8978,  0.0120, -0.0013,  ...,  0.0124,  0.0028, -0.0152],\n                     device='cuda:0')),\n             ('net.layer4.2.bn3.running_mean',\n              tensor([-0.3408, -1.5496,  2.5007,  ...,  1.7487, -0.9159,  2.5313],\n                     device='cuda:0')),\n             ('net.layer4.2.bn3.running_var',\n              tensor([0.9061, 1.9311, 4.7858,  ..., 1.3388, 1.0534, 1.8642], device='cuda:0')),\n             ('net.layer4.2.bn3.num_batches_tracked',\n              tensor(73919, device='cuda:0')),\n             ('net.fc.weight',\n              tensor([[ 0.0001,  0.0320,  0.0161,  ...,  0.0156,  0.0180, -0.0299]],\n                     device='cuda:0')),\n             ('net.fc.bias', tensor([-0.0024], device='cuda:0'))])"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "ckpt['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594811440389",
   "display_name": "Python 3.7.4 64-bit ('brainage': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}