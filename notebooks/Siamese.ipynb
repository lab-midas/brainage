{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# Disable eager execution (otherwise there are problems with prob. conv layers)\n",
    "from tensorflow.python.framework.ops import disable_eager_execution, enable_eager_execution\n",
    "enable_eager_execution()\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '/mnt/home/raheppt1/projects/age_prediction')\n",
    "import yaml\n",
    "import numpy as np\n",
    "import datetime\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "# tensorflow-gpu 2.1.0\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import *\n",
    "\n",
    "from dataset import AgeData\n",
    "from models.models3d import age_regression_models\n",
    "from misc.utils import init_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = [100, 120, 100]\n",
    "image_spacing = [1.5, 1.5, 1.5]\n",
    "batch_size = 16    \n",
    "shuffle_buffer_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 416 ids\n",
      "loaded 47 ids\n"
     ]
    }
   ],
   "source": [
    "# Load training and validation data.\n",
    "age_data = AgeData(image_size,\n",
    "                   image_spacing,\n",
    "                   shuffle_training_images=True,\n",
    "                   save_debug_images=False)\n",
    "dataset_train = age_data.dataset_train()\n",
    "train_samples = dataset_train.num_entries()\n",
    "dataset_val = age_data.dataset_val()\n",
    "val_samples = dataset_val.num_entries()\n",
    "\n",
    "# Define training and validation datasets from generators.\n",
    "def train_gen():\n",
    "    data = dataset_train\n",
    "    i = 0\n",
    "    while i < data.num_entries():\n",
    "        sample = data.get_next()\n",
    "        # DHWC tensor format\n",
    "        image = sample['generators']['image'].transpose([1, 2, 3, 0])\n",
    "        image = image.astype('float32')\n",
    "        age = sample['generators']['age']\n",
    "        yield image, age\n",
    "        i += 1\n",
    "\n",
    "def val_gen():\n",
    "    data = dataset_val\n",
    "    i = 0\n",
    "    while i < data.num_entries():\n",
    "        sample = data.get_next()\n",
    "        image = sample['generators']['image'].transpose([1, 2, 3, 0])\n",
    "        image = image.astype('float32')\n",
    "        age = sample['generators']['age']\n",
    "        yield image, age\n",
    "        i += 1\n",
    "\n",
    "ds_train = tf.data.Dataset.from_generator(train_gen,\n",
    "                                          output_types=(tf.float32, tf.float32),\n",
    "                                          output_shapes=(tf.TensorShape((None, None, None, None)),\n",
    "                                                         tf.TensorShape((1,))))\n",
    "# todo repeat ???? shuffle foreach epoch?\n",
    "ds_train = ds_train.repeat().batch(batch_size=batch_size)\n",
    "ds_train_a = ds_train.shard(num_shards=2, index=0) \n",
    "ds_train_b = ds_train.shard(num_shards=2, index=1) \n",
    "\n",
    "ds_val = tf.data.Dataset.from_generator(val_gen,\n",
    "                                        output_types=(tf.float32, tf.float32),\n",
    "                                        output_shapes=(tf.TensorShape((None, None, None, None)),\n",
    "                                                       tf.TensorShape((1,))))\n",
    "ds_val = ds_val.repeat().shuffle(buffer_size=shuffle_buffer_size).batch(batch_size=batch_size)\n",
    "ds_val_a = ds_val.shard(num_shards=2, index=0) \n",
    "ds_val_b = ds_val.shard(num_shards=2, index=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoder(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(8, kernel_size=(3, 3, 3),  padding='same', input_shape=input_shape))\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(Conv3D(16, kernel_size=(3, 3, 3), padding='same'))\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(Conv3D(32, kernel_size=(3, 3, 3), padding='same'))\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(Conv3D(64, kernel_size=(3, 3, 3), padding='same'))\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(Conv3D(128, kernel_size=(3, 3, 3), padding='same'))\n",
    "    model.add(ReLU())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "    model.add(Flatten())\n",
    "    return model\n",
    "\n",
    "def create_common_dense_layers(dropout,\n",
    "                               lambda_l2,\n",
    "                               outputs):\n",
    "    model = Sequential()\n",
    "    if dropout:\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add(Dense(1024, activation='relu',\n",
    "                    kernel_regularizer=tf.keras.regularizers.l2(lambda_l2)))\n",
    "    if dropout:\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation='relu',\n",
    "                    kernel_regularizer=tf.keras.regularizers.l2(lambda_l2)))\n",
    "    if dropout:\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add(Dense(outputs, activation='linear'))\n",
    "    return model\n",
    "\n",
    "class Siamese(tf.keras.Model):\n",
    "  def __init__(self, \n",
    "               input_shape,\n",
    "               dropout=False,\n",
    "               lambda_l2=0.0,\n",
    "               outputs=1):\n",
    "    super(Siamese, self).__init__()\n",
    "    self.encoder = create_encoder(input_shape)\n",
    "    self.common_dense = create_common_dense_layers(dropout, lambda_l2, outputs)\n",
    "\n",
    "  def call(self, x_a, x_b):\n",
    "    z_a = self.encoder(x_a)\n",
    "    z_b = self.encoder(x_b)\n",
    "    z = tf.concat([z_a, z_b], axis=1)\n",
    "    y = self.common_dense(z)\n",
    "    return y\n",
    "\n",
    "\n",
    "siamese_model = Siamese(image_size + [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-17.17454  ]\n",
      " [  8.454481 ]\n",
      " [-19.956192 ]\n",
      " [-14.666664 ]\n",
      " [  3.526352 ]\n",
      " [  6.652977 ]\n",
      " [-26.861053 ]\n",
      " [ 12.388775 ]\n",
      " [  4.416155 ]\n",
      " [  7.5154037]\n",
      " [ -7.008896 ]\n",
      " [ -1.7111549]\n",
      " [ 13.971252 ]\n",
      " [ 17.831623 ]\n",
      " [ -6.140999 ]\n",
      " [ 11.121151 ]], shape=(16, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[46.431213]\n",
      " [29.779604]\n",
      " [58.99247 ]\n",
      " [70.24777 ]\n",
      " [58.568104]\n",
      " [54.21492 ]\n",
      " [76.78029 ]\n",
      " [38.902122]\n",
      " [28.933607]\n",
      " [64.75017 ]\n",
      " [53.305954]\n",
      " [60.84052 ]\n",
      " [34.283367]\n",
      " [21.566051]\n",
      " [54.19302 ]\n",
      " [58.568104]], shape=(16, 1), dtype=float32)\n",
      "1\n",
      "tf.Tensor(\n",
      "[[-0.01092665]\n",
      " [-0.01960653]\n",
      " [-0.00202544]\n",
      " [-0.01143807]\n",
      " [-0.01995041]\n",
      " [-0.01205333]\n",
      " [ 0.0108896 ]\n",
      " [-0.034601  ]\n",
      " [-0.00402762]\n",
      " [-0.01382279]\n",
      " [-0.01654757]\n",
      " [-0.03232229]\n",
      " [-0.02265441]\n",
      " [-0.01112285]\n",
      " [-0.02781778]\n",
      " [ 0.00093283]\n",
      " [-0.01609883]\n",
      " [-0.00944746]\n",
      " [-0.01273163]\n",
      " [-0.00381302]\n",
      " [-0.00639603]\n",
      " [-0.00703232]\n",
      " [-0.01882287]\n",
      " [-0.00832454]\n",
      " [-0.01213564]\n",
      " [-0.03545582]\n",
      " [-0.01957696]\n",
      " [-0.00746209]\n",
      " [-0.0180815 ]\n",
      " [-0.01520977]\n",
      " [ 0.00955016]\n",
      " [-0.02290829]], shape=(32, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ -9.620808  ]\n",
      " [  0.94729614]\n",
      " [ 10.598221  ]\n",
      " [-29.086926  ]\n",
      " [-37.54141   ]\n",
      " [-10.0643425 ]\n",
      " [  6.7624893 ]\n",
      " [ -4.2710476 ]\n",
      " [ 40.43258   ]\n",
      " [-14.239563  ]\n",
      " [  3.7645454 ]\n",
      " [ 31.945244  ]\n",
      " [-17.407257  ]\n",
      " [-40.161533  ]\n",
      " [-23.392197  ]\n",
      " [  0.86242676]], shape=(16, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[63.18686 ]\n",
      " [25.451061]\n",
      " [45.229294]\n",
      " [51.65777 ]\n",
      " [69.13347 ]\n",
      " [69.067764]\n",
      " [62.08898 ]\n",
      " [24.342232]\n",
      " [29.114305]\n",
      " [75.827515]\n",
      " [26.924025]\n",
      " [40.361397]\n",
      " [41.12252 ]\n",
      " [80.16975 ]\n",
      " [53.535934]\n",
      " [69.28131 ]], shape=(16, 1), dtype=float32)\n",
      "2\n",
      "tf.Tensor(\n",
      "[[-0.02197858]\n",
      " [-0.01342605]\n",
      " [-0.02058891]\n",
      " [-0.01193384]\n",
      " [-0.01808962]\n",
      " [-0.01533252]\n",
      " [-0.00881723]\n",
      " [-0.00955934]\n",
      " [-0.01307179]\n",
      " [-0.01677092]\n",
      " [-0.00650522]\n",
      " [-0.00043304]\n",
      " [-0.00250344]\n",
      " [-0.00963599]\n",
      " [ 0.0127428 ]\n",
      " [-0.01263715]\n",
      " [-0.01490052]\n",
      " [ 0.01074451]\n",
      " [-0.0082574 ]\n",
      " [-0.01979154]\n",
      " [-0.01165154]\n",
      " [-0.01964524]\n",
      " [ 0.00507398]\n",
      " [-0.01342963]\n",
      " [-0.0065626 ]\n",
      " [-0.010492  ]\n",
      " [-0.01573358]\n",
      " [-0.01169442]\n",
      " [-0.01013022]\n",
      " [-0.01148992]\n",
      " [-0.0150414 ]\n",
      " [-0.01094036]], shape=(32, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 33.01027  ]\n",
      " [ 17.054073 ]\n",
      " [ -6.3846703]\n",
      " [-14.351814 ]\n",
      " [ 36.11499  ]\n",
      " [-36.358658 ]\n",
      " [  5.5633125]\n",
      " [-32.492813 ]\n",
      " [ -3.59206  ]\n",
      " [ 11.906914 ]\n",
      " [ 24.235458 ]\n",
      " [ -8.643398 ]\n",
      " [-58.27242  ]\n",
      " [ -5.1006126]\n",
      " [ -9.344284 ]\n",
      " [ 25.629023 ]], shape=(16, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[40.528404]\n",
      " [41.229294]\n",
      " [54.48597 ]\n",
      " [58.376453]\n",
      " [29.738535]\n",
      " [74.63655 ]\n",
      " [51.65777 ]\n",
      " [74.01232 ]\n",
      " [37.828884]\n",
      " [54.425735]\n",
      " [41.09514 ]\n",
      " [55.540043]\n",
      " [83.45791 ]\n",
      " [67.16222 ]\n",
      " [62.425735]\n",
      " [24.895277]], shape=(16, 1), dtype=float32)\n",
      "3\n",
      "tf.Tensor(\n",
      "[[-0.03164149]\n",
      " [-0.01693542]\n",
      " [-0.01110505]\n",
      " [-0.01069085]\n",
      " [-0.00263122]\n",
      " [-0.02386234]\n",
      " [-0.01570604]\n",
      " [-0.01340038]\n",
      " [-0.00355471]\n",
      " [-0.00889575]\n",
      " [-0.01944065]\n",
      " [-0.00853927]\n",
      " [-0.01591409]\n",
      " [-0.01402692]\n",
      " [-0.0035499 ]\n",
      " [-0.01463496]\n",
      " [ 0.0009075 ]\n",
      " [-0.00577049]\n",
      " [-0.01452301]\n",
      " [-0.02686452]\n",
      " [-0.00320958]\n",
      " [-0.02059633]\n",
      " [-0.0211029 ]\n",
      " [-0.00402231]\n",
      " [-0.0309035 ]\n",
      " [-0.0100247 ]\n",
      " [-0.00768266]\n",
      " [-0.00142724]\n",
      " [-0.01802871]\n",
      " [ 0.00391749]\n",
      " [-0.01700519]\n",
      " [-0.02806662]], shape=(32, 1), dtype=float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-b856edbe2a5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msample_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_b\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_train_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_train_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mimages_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimages_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlabels_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 3 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    664\u001b[0m     \u001b[0;34m\"\"\"Returns a nested structure of `Tensor`s containing the next element.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.4/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next_sync\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2657\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m         \u001b[0;34m\"IteratorGetNextSync\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m         \"output_types\", output_types, \"output_shapes\", output_shapes)\n\u001b[0m\u001b[1;32m   2660\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for sample_a, sample_b in tf.data.Dataset.zip((ds_train_a, ds_train_b)):\n",
    "    images_a = sample_a[0]\n",
    "    images_b = sample_b[0]\n",
    "    labels_a = sample_a[1]\n",
    "    labels_b = sample_b[1]\n",
    "    print(labels_a-labels_b)\n",
    "    print(labels_b)\n",
    "    i=i+1\n",
    "    print(i)\n",
    "    y = siamese_model(images_a, images_b)\n",
    "    print(y)\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Siamese\n",
    "# ADNI/IXI Selection - Test vs. validate\n",
    "# Motion Blurring Test \n",
    "# Swicht test / Validate\n",
    "# Select run \n",
    "# Test results test on ADNI (covariate shift)\n",
    "# Test MAP / Alleatoric - visualize\n",
    "# scale callback - shuffle data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
